{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import wraps\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.layers import Conv2D, Add, ZeroPadding2D, UpSampling2D, Concatenate, MaxPooling2D\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from keras_yolo4.yolo4.utils import compose\n",
    "\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from tensorflow.keras.layers import Input, Lambda\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "from keras_yolo4.callback_eval import Evaluate\n",
    "from keras_yolo4.decode_np import Decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=============================\n",
    "import random as rn\n",
    "\n",
    "seed_num = 0\n",
    "np.random.seed(seed_num)\n",
    "rn.seed(seed_num)\n",
    "tf.random.set_seed(seed_num)\n",
    "#============================="
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mish activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mish(Layer):\n",
    "    '''\n",
    "    Mish Activation Function.\n",
    "    .. math::\n",
    "        mish(x) = x * tanh(softplus(x)) = x * tanh(ln(1 + e^{x}))\n",
    "    Shape:\n",
    "        - Input: Arbitrary. Use the keyword argument `input_shape`\n",
    "        (tuple of integers, does not include the samples axis)\n",
    "        when using this layer as the first layer in a model.\n",
    "        - Output: Same shape as the input.\n",
    "    Examples:\n",
    "        >>> X_input = Input(input_shape)\n",
    "        >>> X = Mish()(X_input)\n",
    "    '''\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Mish, self).__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs * K.tanh(K.softplus(inputs))\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(Mish, self).get_config()\n",
    "        return config\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSPDarknet53 backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional Layer의 파라미터를 Darknet 프레임 워크의 설정에 맞게 설정해주는 Wrapper 함수\n",
    "# 주어진 파라미터에 대해 'Conv2D' 함수를 호출하며 'kernel_initializer'와 'padding' 파라미터를 Darknet 프레임워크의\n",
    "# 설정에 맞게 조정한 후 'Conv2D'함수를 실행\n",
    "@wraps(Conv2D)\n",
    "def DarknetConv2D(*args, **kwargs):\n",
    "    \"\"\"Wrapper to set Darknet parameters for Convolution2D.\"\"\"\n",
    "    darknet_conv_kwargs = {}\n",
    "    darknet_conv_kwargs['kernel_initializer'] = keras.initializers.RandomNormal(mean=0.0, stddev=0.01) \n",
    "    # 평균 0, 표준편차 0.01로 초기화\n",
    "    darknet_conv_kwargs['padding'] = 'valid' if kwargs.get('strides')==(2,2) else 'same'\n",
    "    darknet_conv_kwargs.update(kwargs)\n",
    "    return Conv2D(*args, **darknet_conv_kwargs)\n",
    "\n",
    "# DarknetConv2D 함수를 이용해서 Convolutional Layer, BatchNormalization Layer, Activation Layer \n",
    "# 등을 조합하여 레이어를 구성하는 함수\n",
    "# LeakyReLU 또는 Mish 함수를 Activation Layer로 사용\n",
    "def DarknetConv2D_BN_Leaky(*args, **kwargs):\n",
    "    \"\"\"Darknet Convolution2D followed by BatchNormalization and LeakyReLU.\"\"\"\n",
    "    no_bias_kwargs = {'use_bias': False}\n",
    "    no_bias_kwargs.update(kwargs)\n",
    "    return compose(\n",
    "        DarknetConv2D(*args, **no_bias_kwargs),\n",
    "        BatchNormalization(),  # 배치 정규화\n",
    "        LeakyReLU(alpha=0.1))  # leaky relu 사용\n",
    "        # compose 함수는 임의의 개수의 함수를 인수로 받아서 그 함수들의 합성된 결과인 새로운 함수를 반환한다.\n",
    "        \n",
    "def DarknetConv2D_BN_Mish(*args, **kwargs):\n",
    "    \"\"\"Darknet Convolution2D followed by BatchNormalization and LeakyReLU.\"\"\"\n",
    "    no_bias_kwargs = {'use_bias': False}\n",
    "    no_bias_kwargs.update(kwargs)\n",
    "    return compose(\n",
    "        DarknetConv2D(*args, **no_bias_kwargs),\n",
    "        BatchNormalization(),\n",
    "        Mish())  # Mish 사용\n",
    "\n",
    "# Residual Block을 구성하는 함수로, \n",
    "# Convolutional Layer, BatchNormalization Layer, Activation Layer 등을 조합하여 Residual Block을 생성합니다. \n",
    "# Residual Block은 이전 레이어의 출력값을 현재 레이어의 출력값에 더해줌으로써, 더욱 강력한 모델을 만들 수 있습니다. \n",
    "# all_narrow 인수가 True이면 Residual Block의 출력값의 필터 수가 절반으로 줄어듭니다.\n",
    "def resblock_body(x, num_filters, num_blocks, all_narrow=True):\n",
    "    '''A series of resblocks starting with a downsampling Convolution2D'''\n",
    "    # Darknet uses left and top padding instead of 'same' mode\n",
    "    preconv1 = ZeroPadding2D(((1,0),(1,0)))(x)\n",
    "    preconv1 = DarknetConv2D_BN_Mish(num_filters, (3,3), strides=(2,2))(preconv1) # strides=2  > padding : same\n",
    "    shortconv = DarknetConv2D_BN_Mish(num_filters//2 if all_narrow else num_filters, (1,1))(preconv1)\n",
    "    # short cut convolution\n",
    "    mainconv = DarknetConv2D_BN_Mish(num_filters//2 if all_narrow else num_filters, (1,1))(preconv1)\n",
    "    for i in range(num_blocks):\n",
    "        y = compose(\n",
    "                DarknetConv2D_BN_Mish(num_filters//2, (1,1)), # 1*1 컨볼루션\n",
    "                DarknetConv2D_BN_Mish(num_filters//2 if all_narrow else num_filters, (3,3)))(mainconv) # 3*3 컨볼루션\n",
    "        mainconv = Add()([mainconv,y])\n",
    "    postconv = DarknetConv2D_BN_Mish(num_filters//2 if all_narrow else num_filters, (1,1))(mainconv) # 1*1 컨볼루션\n",
    "    route = Concatenate()([postconv, shortconv]) \n",
    "    return DarknetConv2D_BN_Mish(num_filters, (1,1))(route)\n",
    "\n",
    "# 위에서 생성한 Residual Block을 이용하여 Darknet 네트워크를 구성하는 함수입니다. \n",
    "# 이 함수는 52개의 Convolutional Layer를 가진 네트워크를 생성합니다.\n",
    "def darknet_body(x):\n",
    "    '''Darknent body having 52 Convolution2D layers'''\n",
    "    x = DarknetConv2D_BN_Mish(32, (3,3))(x)\n",
    "    x = resblock_body(x, 64, 1, False)\n",
    "    x = resblock_body(x, 128, 2)\n",
    "    x = resblock_body(x, 256, 8)\n",
    "    x = resblock_body(x, 512, 8)\n",
    "    x = resblock_body(x, 1024, 4)\n",
    "    return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOLO body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DarkNet53 네트워크 기반으로 252개의 레이어를 갖는다.\n",
    "# inputs : 모델의 입력 텐서 / num_anchors : 객체 검출에 사용되는 앵커 박스의 수\n",
    "# num_classes : 검출할 클래스 수\n",
    "def yolo4_body(inputs, num_anchors, num_classes):\n",
    "    \"\"\"Create YOLO_V4 model CNN body in Keras.\"\"\"\n",
    "    darknet = Model(inputs, darknet_body(inputs))\n",
    "\n",
    "    #19x19 head\n",
    "    y19 = DarknetConv2D_BN_Leaky(512, (1,1))(darknet.output)\n",
    "    y19 = DarknetConv2D_BN_Leaky(1024, (3,3))(y19)\n",
    "    y19 = DarknetConv2D_BN_Leaky(512, (1,1))(y19)\n",
    "    # SPP - Spatial Pyramid Pooling : (5,5),(9,9),(13,13) pooling\n",
    "    maxpool1 = MaxPooling2D(pool_size=(13,13), strides=(1,1), padding='same')(y19)\n",
    "    maxpool2 = MaxPooling2D(pool_size=(9,9), strides=(1,1), padding='same')(y19)\n",
    "    maxpool3 = MaxPooling2D(pool_size=(5,5), strides=(1,1), padding='same')(y19)\n",
    "    y19 = Concatenate()([maxpool1, maxpool2, maxpool3, y19])\n",
    "    \n",
    "    # 배치정규화 \n",
    "    y19 = DarknetConv2D_BN_Leaky(512, (1,1))(y19)\n",
    "    y19 = DarknetConv2D_BN_Leaky(1024, (3,3))(y19)\n",
    "    y19 = DarknetConv2D_BN_Leaky(512, (1,1))(y19)\n",
    "    \n",
    "    # upsampling\n",
    "    y19_upsample = compose(DarknetConv2D_BN_Leaky(256, (1,1)), UpSampling2D(2))(y19)\n",
    "    \n",
    "    # FPN\n",
    "    # 19 laryers >> 38 layers\n",
    "    # 38x38 head\n",
    "    y38 = DarknetConv2D_BN_Leaky(256, (1,1))(darknet.layers[204].output)\n",
    "    y38 = Concatenate()([y38, y19_upsample])  \n",
    "    y38 = DarknetConv2D_BN_Leaky(256, (1,1))(y38)\n",
    "    y38 = DarknetConv2D_BN_Leaky(512, (3,3))(y38)\n",
    "    y38 = DarknetConv2D_BN_Leaky(256, (1,1))(y38)\n",
    "    y38 = DarknetConv2D_BN_Leaky(512, (3,3))(y38)\n",
    "    y38 = DarknetConv2D_BN_Leaky(256, (1,1))(y38)\n",
    "\n",
    "    y38_upsample = compose(DarknetConv2D_BN_Leaky(128, (1,1)), UpSampling2D(2))(y38)\n",
    "\n",
    "    # 76x76 head\n",
    "    y76 = DarknetConv2D_BN_Leaky(128, (1,1))(darknet.layers[131].output)\n",
    "    y76 = Concatenate()([y76, y38_upsample])\n",
    "    y76 = DarknetConv2D_BN_Leaky(128, (1,1))(y76)\n",
    "    y76 = DarknetConv2D_BN_Leaky(256, (3,3))(y76)\n",
    "    y76 = DarknetConv2D_BN_Leaky(128, (1,1))(y76)\n",
    "    y76 = DarknetConv2D_BN_Leaky(256, (3,3))(y76)\n",
    "    y76 = DarknetConv2D_BN_Leaky(128, (1,1))(y76)\n",
    "\n",
    "    # PAN - path aggregation network\n",
    "    #76x76 output\n",
    "    y76_output = DarknetConv2D_BN_Leaky(256, (3,3))(y76)\n",
    "    y76_output = DarknetConv2D(num_anchors*(num_classes+5), (1,1))(y76_output)\n",
    "\n",
    "    # 38x38 output\n",
    "    y76_downsample = ZeroPadding2D(((1,0),(1,0)))(y76)\n",
    "    y76_downsample = DarknetConv2D_BN_Leaky(256, (3,3), strides=(2,2))(y76_downsample)\n",
    "    y38 = Concatenate()([y76_downsample, y38])\n",
    "    y38 = DarknetConv2D_BN_Leaky(256, (1,1))(y38)\n",
    "    y38 = DarknetConv2D_BN_Leaky(512, (3,3))(y38)\n",
    "    y38 = DarknetConv2D_BN_Leaky(256, (1,1))(y38)\n",
    "    y38 = DarknetConv2D_BN_Leaky(512, (3,3))(y38)\n",
    "    y38 = DarknetConv2D_BN_Leaky(256, (1,1))(y38)\n",
    "\n",
    "    y38_output = DarknetConv2D_BN_Leaky(512, (3,3))(y38)\n",
    "    y38_output = DarknetConv2D(num_anchors*(num_classes+5), (1,1))(y38_output)\n",
    "\n",
    "    # 19x19 output\n",
    "    y38_downsample = ZeroPadding2D(((1,0),(1,0)))(y38)\n",
    "    y38_downsample = DarknetConv2D_BN_Leaky(512, (3,3), strides=(2,2))(y38_downsample)\n",
    "    y19 = Concatenate()([y38_downsample, y19])\n",
    "    y19 = DarknetConv2D_BN_Leaky(512, (1,1))(y19)\n",
    "    y19 = DarknetConv2D_BN_Leaky(1024, (3,3))(y19)\n",
    "    y19 = DarknetConv2D_BN_Leaky(512, (1,1))(y19)\n",
    "    y19 = DarknetConv2D_BN_Leaky(1024, (3,3))(y19)\n",
    "    y19 = DarknetConv2D_BN_Leaky(512, (1,1))(y19)\n",
    "\n",
    "    y19_output = DarknetConv2D_BN_Leaky(1024, (3,3))(y19)\n",
    "    y19_output = DarknetConv2D(num_anchors*(num_classes+5), (1,1))(y19_output)\n",
    "\n",
    "    yolo4_model = Model(inputs, [y19_output, y38_output, y76_output])  \n",
    "    # y19_output : large box, y38_output : medium box, y76_output : small box\n",
    "\n",
    "    return yolo4_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOLO loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIOU 구하는 함수\n",
    "def bbox_ciou(boxes1, boxes2):\n",
    "    '''\n",
    "    caluate ciou = iou - p2/c2 - av\n",
    "    : (batch_size, grid_r, grid_c, anchor, box)\n",
    "    :param boxes1: (8, 13, 13, 3, 4)   pred_xywh\n",
    "    :param boxes2: (8, 13, 13, 3, 4)   label_xywh  \n",
    "    :return:\n",
    "    # anchor는 3개(large, medium, small) 총 9개 \n",
    "    For example, assume that the shapes of pred_xywh and label_xywh are both (1, 4)\n",
    "    '''\n",
    "\n",
    "    # convert to the upper left corner coordinate, the lower right corner coordinate\n",
    "    # x, y, w, h \n",
    "    # 왼쪽위 좌표와 오른쪽 아래 좌표로 변환\n",
    "    boxes1_x0y0x1y1 = tf.concat([boxes1[..., :2] - boxes1[..., 2:] * 0.5,\n",
    "                                 boxes1[..., :2] + boxes1[..., 2:] * 0.5], axis=-1)\n",
    "    boxes2_x0y0x1y1 = tf.concat([boxes2[..., :2] - boxes2[..., 2:] * 0.5,\n",
    "                                 boxes2[..., :2] + boxes2[..., 2:] * 0.5], axis=-1)\n",
    "    '''\n",
    "    Compare boxes1_x0y0x1y1[..., :2] and boxes1_x0y0x1y1[..., 2:] position by position, that is, compare [x0, y0] and [x1, y1] position by position, leaving the smaller ones.\n",
    "    For example, leaving [x0, y0]\n",
    "    This step is to avoid that w h is a negative number at the beginning, causing x0y0 to become the coordinates of the lower right corner and x1y1 to become the coordinates of the upper left corner.\n",
    "    '''\n",
    "    boxes1_x0y0x1y1 = tf.concat([tf.minimum(boxes1_x0y0x1y1[..., :2], boxes1_x0y0x1y1[..., 2:]),\n",
    "                                 tf.maximum(boxes1_x0y0x1y1[..., :2], boxes1_x0y0x1y1[..., 2:])], axis=-1)\n",
    "    boxes2_x0y0x1y1 = tf.concat([tf.minimum(boxes2_x0y0x1y1[..., :2], boxes2_x0y0x1y1[..., 2:]),\n",
    "                                 tf.maximum(boxes2_x0y0x1y1[..., :2], boxes2_x0y0x1y1[..., 2:])], axis=-1)\n",
    "\n",
    "    # The area of the two rectangles\n",
    "    # 두 직사각형의 면적\n",
    "    boxes1_area = (boxes1_x0y0x1y1[..., 2] - boxes1_x0y0x1y1[..., 0]) * (\n",
    "                boxes1_x0y0x1y1[..., 3] - boxes1_x0y0x1y1[..., 1])\n",
    "    boxes2_area = (boxes2_x0y0x1y1[..., 2] - boxes2_x0y0x1y1[..., 0]) * (\n",
    "                boxes2_x0y0x1y1[..., 3] - boxes2_x0y0x1y1[..., 1])\n",
    "\n",
    "    # The coordinates of the upper left corner and the lower right corner of the intersecting rectangle, the shapes are both (8, 13, 13, 3, 2)\n",
    "    # 교차하는 사각형의 왼쪽 위 모서리와 오른쪽 아래 모서리의 좌표, 모양은 모두(8, 13, 13, 3, 2)이다.\n",
    "    left_up = tf.maximum(boxes1_x0y0x1y1[..., :2], boxes2_x0y0x1y1[..., :2])\n",
    "    right_down = tf.minimum(boxes1_x0y0x1y1[..., 2:], boxes2_x0y0x1y1[..., 2:])\n",
    "\n",
    "    # The area of the intersecting rectangle inter_area. iou\n",
    "    # 교차 사각형 겹치는 영역 iou 계산\n",
    "    inter_section = tf.maximum(right_down - left_up, 0.0)\n",
    "    inter_area = inter_section[..., 0] * inter_section[..., 1]\n",
    "    union_area = boxes1_area + boxes2_area - inter_area\n",
    "    iou = inter_area / (union_area + K.epsilon())\n",
    "\n",
    "    # The coordinates of the upper left corner and the lower right corner of the enclosing rectangle, the shape is (8, 13, 13, 3, 2)\n",
    "    # 둘러싸는 사각형의 왼쪽 위 모서리와 오른쪽 아래 모서리의 좌표, 모양은 (8, 13, 13, 3, 2)입니다.\n",
    "    enclose_left_up = tf.minimum(boxes1_x0y0x1y1[..., :2], boxes2_x0y0x1y1[..., :2])\n",
    "    enclose_right_down = tf.maximum(boxes1_x0y0x1y1[..., 2:], boxes2_x0y0x1y1[..., 2:])\n",
    "\n",
    "    # DIoU 계산\n",
    "\n",
    "    # The square of the diagonal of the enclosing rectangle\n",
    "    # 둘러싸는 직사각형의 대각선의 제곱\n",
    "    enclose_wh = enclose_right_down - enclose_left_up\n",
    "    enclose_c2 = K.pow(enclose_wh[..., 0], 2) + K.pow(enclose_wh[..., 1], 2)\n",
    "    \n",
    "    # The square of the distance between the center points of the two rectangles\n",
    "    p2 = K.pow(boxes1[..., 0] - boxes2[..., 0], 2) + K.pow(boxes1[..., 1] - boxes2[..., 1], 2)\n",
    "\n",
    "    # Increase av. Add division by 0 protection to prevent nan.\n",
    "    # 두 직사각형의 중심점 사이 거리의 제곱\n",
    "    atan1 = tf.atan(boxes1[..., 2] / (boxes1[..., 3] + K.epsilon()))\n",
    "    atan2 = tf.atan(boxes2[..., 2] / (boxes2[..., 3] + K.epsilon()))\n",
    "    v = 4.0 * K.pow(atan1 - atan2, 2) / (math.pi ** 2)\n",
    "    a = v / (1 - iou + v)\n",
    "\n",
    "    # ciou loss = 1 - ciou\n",
    "    ciou = iou - 1.0 * p2 / enclose_c2 - 1.0 * a * v\n",
    "    return ciou\n",
    "\n",
    "#IOU 계산 함수\n",
    "def bbox_iou(boxes1, boxes2):\n",
    "    '''\n",
    "    Measuring frame boxes1 (?, grid_h, grid_w, 3, 1, 4), the output of the neural network (tx, ty, tw, th) is obtained by post-processing (bx, by, bw, bh)\n",
    "    All gt boxes2 in the picture (?, 1, 1, 1, 150, 4)\n",
    "    '''\n",
    "    boxes1_area = boxes1[..., 2] * boxes1[..., 3]  # Area of 3 prediction boxes of all grids\n",
    "    boxes2_area = boxes2[..., 2] * boxes2[..., 3]  # The area of all ground truth\n",
    "\n",
    "    # (x, y, w, h) to (x0, y0, x1, y1)\n",
    "    boxes1 = tf.concat([boxes1[..., :2] - boxes1[..., 2:] * 0.5,\n",
    "                        boxes1[..., :2] + boxes1[..., 2:] * 0.5], axis=-1)\n",
    "    boxes2 = tf.concat([boxes2[..., :2] - boxes2[..., 2:] * 0.5,\n",
    "                        boxes2[..., :2] + boxes2[..., 2:] * 0.5], axis=-1)\n",
    "\n",
    "    # 3 prediction boxes with grids and 150 ground truth calculation iou respectively. So the shape of left_up and right_down = (?, grid_h, grid_w, 3, 150, 2)\n",
    "    left_up = tf.maximum(boxes1[..., :2], boxes2[..., :2])  # The coordinates of the upper left corner of the intersecting rectangle\n",
    "    right_down = tf.minimum(boxes1[..., 2:], boxes2[..., 2:])  # The coordinates of the lower right corner of the intersecting rectangle\n",
    "\n",
    "    inter_section = tf.maximum(right_down - left_up, 0.0)  # The w and h of the intersecting rectangle are 0 when they are negative (?, grid_h, grid_w, 3, 150, 2)\n",
    "    inter_area = inter_section[..., 0] * inter_section[..., 1]  # Area of the intersecting rectangle (?, grid_h, grid_w, 3, 150)\n",
    "    union_area = boxes1_area + boxes2_area - inter_area  # union_area      (?, grid_h, grid_w, 3, 150)\n",
    "    iou = 1.0 * inter_area / union_area  # iou                             (?, grid_h, grid_w, 3, 150)\n",
    "    return iou\n",
    "\n",
    "# 손실 함수 계산 부분\n",
    "# 입력으로는 모델이 예측한 conv feature map, 예측한 bounding box 위치와 클래스, \n",
    "# 그리고 ground truth로 제공되는 bounding box 위치와 클래스 등이 있습니다. \n",
    "# 이 정보들을 바탕으로 confidence loss, classification loss, bbox regression loss를 계산합니다.\n",
    "def loss_layer(conv, pred, label, bboxes, stride, num_class, iou_loss_thresh):\n",
    "    conv_shape = tf.shape(conv)\n",
    "    batch_size = conv_shape[0]\n",
    "    output_size = conv_shape[1]\n",
    "    input_size = stride * output_size\n",
    "    conv = tf.reshape(conv, (batch_size, output_size, output_size,\n",
    "                             3, 5 + num_class))\n",
    "    conv_raw_prob = conv[:, :, :, :, 5:]\n",
    "\n",
    "    pred_xywh = pred[:, :, :, :, 0:4]  # x, y, w, h\n",
    "    pred_conf = pred[:, :, :, :, 4:5]  # confidence score\n",
    "\n",
    "    label_xywh = label[:, :, :, :, 0:4]\n",
    "    respond_bbox = label[:, :, :, :, 4:5]\n",
    "    label_prob = label[:, :, :, :, 5:]  # class probability\n",
    "\n",
    "    ciou = tf.expand_dims(bbox_ciou(pred_xywh, label_xywh), axis=-1)  # (8, 13, 13, 3, 1)\n",
    "    input_size = tf.cast(input_size, tf.float32)\n",
    "\n",
    "    # The weight of each prediction box xxxiou_loss = 2-(ground truth area/picture area)\n",
    "    bbox_loss_scale = 2.0 - 1.0 * label_xywh[:, :, :, :, 2:3] * label_xywh[:, :, :, :, 3:4] / (input_size ** 2)\n",
    "    ciou_loss = respond_bbox * bbox_loss_scale * (1 - ciou) # 1. respond_bbox is used as a mask, xxxiou_loss is calculated only when there is an object\n",
    "    # 1 obj : respond_bbox ,  bbox_loss_scale : lambda scale \n",
    "\n",
    "    # 2. respond_bbox is used as a mask, and the category loss is calculated when there is an object\n",
    "    prob_loss = respond_bbox * tf.nn.sigmoid_cross_entropy_with_logits(labels=label_prob, logits=conv_raw_prob)\n",
    "\n",
    "    # 3. xxxiou_loss and category loss are relatively simple. The important thing is conf_loss, which is a focal_loss\n",
    "    # There are two steps: the first step is to determine which grid_h * grid_w * 3 prediction boxes are used as counterexamples; the second step is to calculate focal_loss.\n",
    "\n",
    "    expand_pred_xywh = pred_xywh[:, :, :, :, np.newaxis, :]  # Expand to (?, grid_h, grid_w, 3,   1, 4)\n",
    "    expand_bboxes = bboxes[:, np.newaxis, np.newaxis, np.newaxis, :, :]  # Expand to (?,      1,      1, 1, 150, 4)\n",
    "    iou = bbox_iou(expand_pred_xywh, expand_bboxes)  # The 3 prediction boxes of all grids and 150 ground truth respectively calculate iou.   (?, grid_h, grid_w, 3, 150\n",
    "    max_iou = tf.expand_dims(tf.reduce_max(iou, axis=-1), axis=-1)  # Among 150 ground truth iou, keep the largest iou. (?, grid_h, grid_w, 3, 1)\n",
    "\n",
    "    # respond_bgd represents whether the grid_h * grid_w * 3 prediction boxes output by this branch are counterexamples (background)\n",
    "    # label has an object, respond_bgd is 0. If there is no object: if the iou with a certain gt (150 in total) exceeds iou_loss_thresh, respond_bgd is 0; if the iou with all gt (150 at most) is less than iou_loss_thresh, respond_bgd is 1.\n",
    "    # respond_bgd is 0 means there is an object, which is not a counterexample; the weight respond_bgd is 1 means there is no object, which is a counterexample.\n",
    "    # Interestingly, due to constant updates during model training, for the same picture, the grid_h * grid_w * 3 prediction boxes (for this branch output) of the two predictions are different. These prediction boxes are used to calculate iou to determine which prediction boxes are counterexamples.\n",
    "    # Instead of using a priori box of fixed size (not fixed position).\n",
    "    respond_bgd = (1.0 - respond_bbox) * tf.cast(max_iou < iou_loss_thresh, tf.float32)\n",
    "\n",
    "    # Binary cross entropy loss\n",
    "    pos_loss = respond_bbox * (0 - K.log(pred_conf + K.epsilon()))\n",
    "    neg_loss = respond_bgd  * (0 - K.log(1 - pred_conf + K.epsilon()))\n",
    "    #pos_loss(positive loss) : object가 1일 때 loss\n",
    "    # neg_loss(negative loss) : object가 없을 때 loss\n",
    "    \n",
    "    conf_loss = pos_loss + neg_loss\n",
    "    # Looking back at respond_bgd, the iou of a certain prediction box and a certain gt exceeds iou_loss_thresh, which is not regarded as a counterexample. When participating in the \"Binary Cross Entropy of Predicted Confidence Level and True Confidence Level\", this box may not be a positive example (if this box is not marked as 1 in the label). This box may not participate in the calculation of confidence loss.\n",
    "    # This kind of box is generally the box near the gt box, or the other two boxes of the grid where the gt box is located. It is neither a positive example nor a negative example. It does not participate in the calculation of the confidence loss. (Called ignore in the paper\n",
    "\n",
    "    ciou_loss = tf.reduce_mean(tf.reduce_sum(ciou_loss, axis=[1, 2, 3, 4]))  # Each sample calculates its own ciou_loss separately, and then averages\n",
    "    conf_loss = tf.reduce_mean(tf.reduce_sum(conf_loss, axis=[1, 2, 3, 4]))  # Each sample calculates its own conf_loss separately, and then averages\n",
    "    prob_loss = tf.reduce_mean(tf.reduce_sum(prob_loss, axis=[1, 2, 3, 4]))  # Each sample calculates its own prob_loss separately, and then averages\n",
    "\n",
    "    return ciou_loss, conf_loss, prob_loss\n",
    "\n",
    "# YOLO의 모델 출력 결과를 scale및 grid에 따라 좌표 복원하기\n",
    "# conf(objectness)와 prob(class probability)에는 sigmoid activation function 적용\n",
    "# 전체가 convolution이라서 부분적으로 activation을 후처리함.\n",
    "\n",
    "# 이 함수는 convolution layer에서 나온 출력 값을 bounding box 좌표와 objectness score, 그리고 클래스 확률 값으로 변환하는 역할을 합니다.\n",
    "def decode(conv_output, anchors, stride, num_class):\n",
    "    conv_shape       = tf.shape(conv_output)\n",
    "    batch_size       = conv_shape[0]\n",
    "    output_size      = conv_shape[1]\n",
    "    anchor_per_scale = len(anchors)\n",
    "    conv_output = tf.reshape(conv_output, (batch_size, output_size, output_size, anchor_per_scale, 5 + num_class)) # 5 = (w, y, w, h, score)\n",
    "    conv_raw_dxdy = conv_output[:, :, :, :, 0:2] # x, y\n",
    "    conv_raw_dwdh = conv_output[:, :, :, :, 2:4] # w, h\n",
    "    conv_raw_conf = conv_output[:, :, :, :, 4:5] # conf, socre\n",
    "    conv_raw_prob = conv_output[:, :, :, :, 5: ] # class probability\n",
    "    y = tf.tile(tf.range(output_size, dtype=tf.int32)[:, tf.newaxis], [1, output_size])\n",
    "    x = tf.tile(tf.range(output_size, dtype=tf.int32)[tf.newaxis, :], [output_size, 1])\n",
    "    xy_grid = tf.concat([x[:, :, tf.newaxis], y[:, :, tf.newaxis]], axis=-1)\n",
    "    xy_grid = tf.tile(xy_grid[tf.newaxis, :, :, tf.newaxis, :], [batch_size, 1, 1, anchor_per_scale, 1])\n",
    "    xy_grid = tf.cast(xy_grid, tf.float32)\n",
    "    pred_xy = (tf.sigmoid(conv_raw_dxdy) + xy_grid) * stride\n",
    "    pred_wh = (tf.exp(conv_raw_dwdh) * anchors) * stride\n",
    "    pred_xywh = tf.concat([pred_xy, pred_wh], axis=-1)\n",
    "    pred_conf = tf.sigmoid(conv_raw_conf)\n",
    "    pred_prob = tf.sigmoid(conv_raw_prob)\n",
    "    return tf.concat([pred_xywh, pred_conf, pred_prob], axis=-1)\n",
    "\n",
    "# 전체 loss 계산 함수\n",
    "\n",
    "def yolo_loss(args, num_classes, iou_loss_thresh, anchors):\n",
    "    conv_lbbox = args[0]   # (?, ?, ?, 3*(num_classes+5)) large box\n",
    "    conv_mbbox = args[1]   # (?, ?, ?, 3*(num_classes+5)) medium box\n",
    "    conv_sbbox = args[2]   # (?, ?, ?, 3*(num_classes+5)) small box\n",
    "    label_sbbox = args[3]   # (?, ?, ?, 3, num_classes+5) \n",
    "    label_mbbox = args[4]   # (?, ?, ?, 3, num_classes+5)\n",
    "    label_lbbox = args[5]   # (?, ?, ?, 3, num_classes+5)\n",
    "    true_sbboxes = args[6]   # (?, 150, 4)\n",
    "    true_mbboxes = args[7]   # (?, 150, 4)\n",
    "    true_lbboxes = args[8]   # (?, 150, 4)\n",
    "    pred_sbbox = decode(conv_sbbox, anchors[0], 8, num_classes)\n",
    "    pred_mbbox = decode(conv_mbbox, anchors[1], 16, num_classes)\n",
    "    pred_lbbox = decode(conv_lbbox, anchors[2], 32, num_classes)\n",
    "    sbbox_ciou_loss, sbbox_conf_loss, sbbox_prob_loss = loss_layer(conv_sbbox, pred_sbbox, label_sbbox, true_sbboxes, 8, num_classes, iou_loss_thresh)\n",
    "    mbbox_ciou_loss, mbbox_conf_loss, mbbox_prob_loss = loss_layer(conv_mbbox, pred_mbbox, label_mbbox, true_mbboxes, 16, num_classes, iou_loss_thresh)\n",
    "    lbbox_ciou_loss, lbbox_conf_loss, lbbox_prob_loss = loss_layer(conv_lbbox, pred_lbbox, label_lbbox, true_lbboxes, 32, num_classes, iou_loss_thresh)\n",
    "\n",
    "    ciou_loss = sbbox_ciou_loss + mbbox_ciou_loss + lbbox_ciou_loss\n",
    "    conf_loss = sbbox_conf_loss + mbbox_conf_loss + lbbox_conf_loss\n",
    "    prob_loss = sbbox_prob_loss + mbbox_prob_loss + lbbox_prob_loss\n",
    "\n",
    "    loss = ciou_loss + conf_loss + prob_loss\n",
    "\n",
    "    loss = tf.compat.v1.Print(loss, [loss, ciou_loss, conf_loss, prob_loss], message=' loss: ')\n",
    "    #tf.print([loss, ciou_loss, conf_loss, prob_loss])\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOLO 전체 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, anchors_stride_base, num_classes, load_pretrained=True, freeze_body=2,\n",
    "            weights_path='model_data/yolo_weights.h5'):\n",
    "    '''create the training model'''\n",
    "    K.clear_session() # get a new session\n",
    "    image_input = Input(shape=(None, None, 3))\n",
    "    h, w = input_shape\n",
    "    num_anchors = len(anchors_stride_base)\n",
    "\n",
    "    max_bbox_per_scale = 150\n",
    "    iou_loss_thresh = 0.7\n",
    "\n",
    "    model_body = yolo4_body(image_input, num_anchors, num_classes)\n",
    "    print('Create YOLOv4 model with {} anchors and {} classes.'.format(num_anchors*3, num_classes))\n",
    "\n",
    "    if load_pretrained:\n",
    "        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
    "        print('Load weights {}.'.format(weights_path))\n",
    "        if freeze_body in [1, 2]:\n",
    "            # Freeze darknet53 body or freeze all but 3 output layers.\n",
    "            num = (250, len(model_body.layers)-3)[freeze_body-1]\n",
    "            for i in range(num): model_body.layers[i].trainable = False\n",
    "            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n",
    "    \n",
    "    # ground truth\n",
    "    y_true = [\n",
    "        layers.Input(name='input_2', shape=(None, None, 3, (num_classes + 5))),  # label_sbbox\n",
    "        layers.Input(name='input_3', shape=(None, None, 3, (num_classes + 5))),  # label_mbbox\n",
    "        layers.Input(name='input_4', shape=(None, None, 3, (num_classes + 5))),  # label_lbbox\n",
    "        layers.Input(name='input_5', shape=(max_bbox_per_scale, 4)),             # true_sbboxes\n",
    "        layers.Input(name='input_6', shape=(max_bbox_per_scale, 4)),             # true_mbboxes\n",
    "        layers.Input(name='input_7', shape=(max_bbox_per_scale, 4))              # true_lbboxes\n",
    "    ]\n",
    "    loss_list = layers.Lambda(yolo_loss, name='yolo_loss',\n",
    "                           arguments={'num_classes': num_classes, 'iou_loss_thresh': iou_loss_thresh,\n",
    "                                      'anchors': anchors_stride_base})([*model_body.output, *y_true])\n",
    "\n",
    "    model = Model([model_body.input, *y_true], loss_list)\n",
    "    #model.summary()\n",
    "\n",
    "    return model, model_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes(classes_path):\n",
    "    '''loads the classes'''\n",
    "    with open(classes_path) as f:\n",
    "        class_names = f.readlines()\n",
    "    class_names = [c.strip() for c in class_names]\n",
    "    return class_names\n",
    "\n",
    "def get_anchors(anchors_path):\n",
    "    '''loads the anchors from a file'''\n",
    "    with open(anchors_path) as f:\n",
    "        anchors = f.readline()\n",
    "    anchors = [float(x) for x in anchors.split(',')]\n",
    "    return np.array(anchors).reshape(-1, 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data augmentation modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_fill(image, bboxes):\n",
    "    if random.random() < 0.5:\n",
    "        h, w, _ = image.shape\n",
    "        # Fill the black border horizontally to train small target detection\n",
    "        if random.random() < 0.5:\n",
    "            dx = random.randint(int(0.5*w), int(1.5*w))\n",
    "            black_1 = np.zeros((h, dx, 3), dtype='uint8')\n",
    "            black_2 = np.zeros((h, dx, 3), dtype='uint8')\n",
    "            image = np.concatenate([black_1, image, black_2], axis=1)\n",
    "            bboxes[:, [0, 2]] += dx\n",
    "        # Fill the black edges vertically to train small target detection\n",
    "        else:\n",
    "            dy = random.randint(int(0.5*h), int(1.5*h))\n",
    "            black_1 = np.zeros((dy, w, 3), dtype='uint8')\n",
    "            black_2 = np.zeros((dy, w, 3), dtype='uint8')\n",
    "            image = np.concatenate([black_1, image, black_2], axis=0)\n",
    "            bboxes[:, [1, 3]] += dy\n",
    "    return image, bboxes\n",
    "\n",
    "def random_horizontal_flip(image, bboxes):\n",
    "    if random.random() < 0.5:\n",
    "        _, w, _ = image.shape\n",
    "        image = image[:, ::-1, :]\n",
    "        bboxes[:, [0,2]] = w - bboxes[:, [2,0]]\n",
    "    return image, bboxes\n",
    "\n",
    "def random_crop(image, bboxes):\n",
    "    if random.random() < 0.5:\n",
    "        h, w, _ = image.shape\n",
    "        max_bbox = np.concatenate([np.min(bboxes[:, 0:2], axis=0), np.max(bboxes[:, 2:4], axis=0)], axis=-1)\n",
    "\n",
    "        max_l_trans = max_bbox[0]\n",
    "        max_u_trans = max_bbox[1]\n",
    "        max_r_trans = w - max_bbox[2]\n",
    "        max_d_trans = h - max_bbox[3]\n",
    "\n",
    "        crop_xmin = max(0, int(max_bbox[0] - random.uniform(0, max_l_trans)))\n",
    "        crop_ymin = max(0, int(max_bbox[1] - random.uniform(0, max_u_trans)))\n",
    "        crop_xmax = max(w, int(max_bbox[2] + random.uniform(0, max_r_trans)))\n",
    "        crop_ymax = max(h, int(max_bbox[3] + random.uniform(0, max_d_trans)))\n",
    "\n",
    "        image = image[crop_ymin : crop_ymax, crop_xmin : crop_xmax]\n",
    "\n",
    "        bboxes[:, [0, 2]] = bboxes[:, [0, 2]] - crop_xmin\n",
    "        bboxes[:, [1, 3]] = bboxes[:, [1, 3]] - crop_ymin\n",
    "    return image, bboxes\n",
    "\n",
    "def random_translate(image, bboxes):\n",
    "    if random.random() < 0.5:\n",
    "        h, w, _ = image.shape\n",
    "        max_bbox = np.concatenate([np.min(bboxes[:, 0:2], axis=0), np.max(bboxes[:, 2:4], axis=0)], axis=-1)\n",
    "\n",
    "        max_l_trans = max_bbox[0]\n",
    "        max_u_trans = max_bbox[1]\n",
    "        max_r_trans = w - max_bbox[2]\n",
    "        max_d_trans = h - max_bbox[3]\n",
    "\n",
    "        tx = random.uniform(-(max_l_trans - 1), (max_r_trans - 1))\n",
    "        ty = random.uniform(-(max_u_trans - 1), (max_d_trans - 1))\n",
    "\n",
    "        M = np.array([[1, 0, tx], [0, 1, ty]])\n",
    "        image = cv2.warpAffine(image, M, (w, h))\n",
    "\n",
    "        bboxes[:, [0, 2]] = bboxes[:, [0, 2]] + tx\n",
    "        bboxes[:, [1, 3]] = bboxes[:, [1, 3]] + ty\n",
    "    return image, bboxes\n",
    "\n",
    "def image_preprocess(image, target_size, gt_boxes):\n",
    "    # The images passed in for training are in rgb format\n",
    "    ih, iw = target_size\n",
    "    h, w = image.shape[:2]\n",
    "    interps = [   # Randomly choose an interpolation method\n",
    "        cv2.INTER_NEAREST,\n",
    "        cv2.INTER_LINEAR,\n",
    "        cv2.INTER_AREA,\n",
    "        cv2.INTER_CUBIC,\n",
    "        cv2.INTER_LANCZOS4,\n",
    "    ]\n",
    "    method = np.random.choice(interps)   # Randomly choose an interpolation method\n",
    "    scale_x = float(iw) / w\n",
    "    scale_y = float(ih) / h\n",
    "    image = cv2.resize(image, None, None, fx=scale_x, fy=scale_y, interpolation=method)\n",
    "\n",
    "    pimage = image.astype(np.float32) / 255.\n",
    "    if gt_boxes is None:\n",
    "        return pimage\n",
    "    else:\n",
    "        gt_boxes[:, [0, 2]] = gt_boxes[:, [0, 2]] * scale_x\n",
    "        gt_boxes[:, [1, 3]] = gt_boxes[:, [1, 3]] * scale_y\n",
    "        return pimage, gt_boxes\n",
    "\n",
    "def parse_annotation(annotation, train_input_size, annotation_type):\n",
    "    line = annotation.split()\n",
    "    image_path = line[0]\n",
    "    if not os.path.exists(image_path):\n",
    "        raise KeyError(\"%s does not exist ... \" %image_path)\n",
    "    image = np.array(cv2.imread(image_path))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # No items are marked, that is, each grid is treated as a background\n",
    "    exist_boxes = True\n",
    "    if len(line) == 1:\n",
    "        bboxes = np.array([[10, 10, 101, 103, 0]])\n",
    "        exist_boxes = False\n",
    "    else:\n",
    "        bboxes = np.array([list(map(lambda x: int(float(x)), box.split(','))) for box in line[1:]])\n",
    "    if annotation_type == 'train':  # annotation이 훈련용 데이터면\n",
    "        # image, bboxes = random_fill(np.copy(image), np.copy(bboxes))    # Open when the dataset lacks small objects\n",
    "        image, bboxes = random_horizontal_flip(np.copy(image), np.copy(bboxes))\n",
    "        image, bboxes = random_crop(np.copy(image), np.copy(bboxes))\n",
    "        image, bboxes = random_translate(np.copy(image), np.copy(bboxes))\n",
    "    image, bboxes = image_preprocess(np.copy(image), [train_input_size, train_input_size], np.copy(bboxes))\n",
    "    return image, bboxes, exist_boxes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(annotation_lines, batch_size, anchors, num_classes, max_bbox_per_scale, annotation_type):\n",
    "    '''data generator for fit_generator'''\n",
    "    n = len(annotation_lines)\n",
    "    i = 0\n",
    "    # Multi-scale training\n",
    "    train_input_sizes = [320, 352, 384, 416 ,448, 480, 512, 544, 576, 608]\n",
    "    strides = np.array([8, 16, 32])\n",
    "\n",
    "    while True:\n",
    "        train_input_size = random.choice(train_input_sizes)\n",
    "\n",
    "        # Number of output grids\n",
    "        train_output_sizes = train_input_size // strides\n",
    "\n",
    "        batch_image = np.zeros((batch_size, train_input_size, train_input_size, 3))\n",
    "\n",
    "        batch_label_sbbox = np.zeros((batch_size, train_output_sizes[0], train_output_sizes[0],\n",
    "                                      3, 5 + num_classes))\n",
    "        batch_label_mbbox = np.zeros((batch_size, train_output_sizes[1], train_output_sizes[1],\n",
    "                                      3, 5 + num_classes))\n",
    "        batch_label_lbbox = np.zeros((batch_size, train_output_sizes[2], train_output_sizes[2],\n",
    "                                      3, 5 + num_classes))\n",
    "\n",
    "        batch_sbboxes = np.zeros((batch_size, max_bbox_per_scale, 4))\n",
    "        batch_mbboxes = np.zeros((batch_size, max_bbox_per_scale, 4))\n",
    "        batch_lbboxes = np.zeros((batch_size, max_bbox_per_scale, 4))\n",
    "\n",
    "        for num in range(batch_size):\n",
    "            if i == 0:\n",
    "                np.random.shuffle(annotation_lines)\n",
    "\n",
    "            image, bboxes, exist_boxes = parse_annotation(annotation_lines[i], train_input_size, annotation_type)\n",
    "            label_sbbox, label_mbbox, label_lbbox, sbboxes, mbboxes, lbboxes = preprocess_true_boxes(bboxes, train_output_sizes, strides, num_classes, max_bbox_per_scale, anchors)\n",
    "\n",
    "            batch_image[num, :, :, :] = image\n",
    "            if exist_boxes:\n",
    "                batch_label_sbbox[num, :, :, :, :] = label_sbbox\n",
    "                batch_label_mbbox[num, :, :, :, :] = label_mbbox\n",
    "                batch_label_lbbox[num, :, :, :, :] = label_lbbox\n",
    "                batch_sbboxes[num, :, :] = sbboxes\n",
    "                batch_mbboxes[num, :, :] = mbboxes\n",
    "                batch_lbboxes[num, :, :] = lbboxes\n",
    "            i = (i + 1) % n\n",
    "        yield [batch_image, batch_label_sbbox, batch_label_mbbox, batch_label_lbbox, batch_sbboxes, batch_mbboxes, batch_lbboxes], np.zeros(batch_size)\n",
    "\n",
    "def data_generator_wrapper(annotation_lines, batch_size, anchors, num_classes, max_bbox_per_scale, annotation_type):\n",
    "    n = len(annotation_lines)\n",
    "    if n==0 or batch_size<=0: return None\n",
    "    return data_generator(annotation_lines, batch_size, anchors, num_classes, max_bbox_per_scale, annotation_type)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ground Truth box 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IOU 계산\n",
    "def bbox_iou_data(boxes1, boxes2):\n",
    "    boxes1 = np.array(boxes1)\n",
    "    boxes2 = np.array(boxes2)\n",
    "    boxes1_area = boxes1[..., 2] * boxes1[..., 3]\n",
    "    boxes2_area = boxes2[..., 2] * boxes2[..., 3]\n",
    "    # x1,y1,x2,y2 ==> x,y,w,h\n",
    "    boxes1 = np.concatenate([boxes1[..., :2] - boxes1[..., 2:] * 0.5,\n",
    "                            boxes1[..., :2] + boxes1[..., 2:] * 0.5], axis=-1)\n",
    "    boxes2 = np.concatenate([boxes2[..., :2] - boxes2[..., 2:] * 0.5,\n",
    "                            boxes2[..., :2] + boxes2[..., 2:] * 0.5], axis=-1)\n",
    "    # 교집합의 좌상\n",
    "    left_up = np.maximum(boxes1[..., :2], boxes2[..., :2])\n",
    "    # 교집합의 우하\n",
    "    right_down = np.minimum(boxes1[..., 2:], boxes2[..., 2:])\n",
    "    inter_section = np.maximum(right_down - left_up, 0.0)\n",
    "    inter_area = inter_section[..., 0] * inter_section[..., 1]\n",
    "    union_area = boxes1_area + boxes2_area - inter_area\n",
    "    return inter_area / union_area\n",
    "\n",
    "# GT boxes를 anchor로 scale을 찾고 해당 scale의 grid와 anchor에 저장\n",
    "def preprocess_true_boxes(bboxes, train_output_sizes, strides, num_classes, max_bbox_per_scale, anchors):\n",
    "    label = [np.zeros((train_output_sizes[i], train_output_sizes[i], 3,\n",
    "                       5 + num_classes)) for i in range(3)]\n",
    "    bboxes_xywh = [np.zeros((max_bbox_per_scale, 4)) for _ in range(3)]\n",
    "    bbox_count = np.zeros((3,))\n",
    "    for bbox in bboxes:\n",
    "        bbox_coor = bbox[:4]\n",
    "        bbox_class_ind = bbox[4]\n",
    "        onehot = np.zeros(num_classes, dtype=float)\n",
    "        onehot[bbox_class_ind] = 1.0\n",
    "        bbox_xywh = np.concatenate([(bbox_coor[2:] + bbox_coor[:2]) * 0.5, bbox_coor[2:] - bbox_coor[:2]], axis=-1)\n",
    "        bbox_xywh_scaled = 1.0 * bbox_xywh[np.newaxis, :] / strides[:, np.newaxis]\n",
    "        # 3단계 크기 중에서 anchor와 가장 매칭되는 곳 찾기\n",
    "        iou = []\n",
    "        for i in range(3):\n",
    "            anchors_xywh = np.zeros((3, 4))\n",
    "            anchors_xywh[:, 0:2] = np.floor(bbox_xywh_scaled[i, 0:2]).astype(np.int32) + 0.5\n",
    "            anchors_xywh[:, 2:4] = anchors[i]\n",
    "            iou_scale = bbox_iou_data(bbox_xywh_scaled[i][np.newaxis, :], anchors_xywh)\n",
    "            iou.append(iou_scale)\n",
    "        best_anchor_ind = np.argmax(np.array(iou).reshape(-1), axis=-1)\n",
    "        best_detect = int(best_anchor_ind / 3)\n",
    "        best_anchor = int(best_anchor_ind % 3)\n",
    "        xind, yind = np.floor(bbox_xywh_scaled[best_detect, 0:2]).astype(np.int32)\n",
    "        # Prevent crossing\n",
    "        grid_r = label[best_detect].shape[0]\n",
    "        grid_c = label[best_detect].shape[1]\n",
    "        xind = max(0, xind)\n",
    "        yind = max(0, yind)\n",
    "        xind = min(xind, grid_r-1)\n",
    "        yind = min(yind, grid_c-1)\n",
    "        # bbox[4], objectness, class GT\n",
    "        label[best_detect][yind, xind, best_anchor, :] = 0\n",
    "        label[best_detect][yind, xind, best_anchor, 0:4] = bbox_xywh\n",
    "        label[best_detect][yind, xind, best_anchor, 4:5] = 1.0\n",
    "        label[best_detect][yind, xind, best_anchor, 5:] = onehot\n",
    "        bbox_ind = int(bbox_count[best_detect] % max_bbox_per_scale)\n",
    "        bboxes_xywh[best_detect][bbox_ind, :4] = bbox_xywh\n",
    "        bbox_count[best_detect] += 1\n",
    "    label_sbbox, label_mbbox, label_lbbox = label\n",
    "    sbboxes, mbboxes, lbboxes = bboxes_xywh\n",
    "    return label_sbbox, label_mbbox, label_lbbox, sbboxes, mbboxes, lbboxes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _main():\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "      try:\n",
    "        for gpu in gpus:\n",
    "          tf.config.experimental.set_memory_growth(gpu, True)\n",
    "      except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "    print('Please visit https://github.com/miemie2013/Keras-YOLOv4 for more complete model!')\n",
    "\n",
    "    annotation_train_path = 'train.txt'\n",
    "    annotation_val_path = 'val.txt'\n",
    "    #annotation_train_path = '2007_train.txt'\n",
    "    #annotation_val_path = '2007_val.txt'\n",
    "    log_dir = 'logs/000/'\n",
    "    classes_path = 'classes.txt'\n",
    "    anchors_path = 'keras_yolo4/model_data/yolo4_anchors.txt'\n",
    "    class_names = get_classes(classes_path)\n",
    "    num_classes = len(class_names)\n",
    "    class_index = ['{}'.format(i) for i in range(num_classes)]\n",
    "    anchors = get_anchors(anchors_path)\n",
    "\n",
    "    max_bbox_per_scale = 150\n",
    "\n",
    "    anchors_stride_base = np.array([\n",
    "        [[12, 16], [19, 36], [40, 28]],\n",
    "        [[36, 75], [76, 55], [72, 146]],\n",
    "        [[142, 110], [192, 243], [459,401]]#[459,401]\n",
    "    ])\n",
    "    # Some preprocessing\n",
    "    anchors_stride_base = anchors_stride_base.astype(np.float32)\n",
    "    anchors_stride_base[0] /= 8\n",
    "    anchors_stride_base[1] /= 16\n",
    "    anchors_stride_base[2] /= 32\n",
    "\n",
    "    input_shape = (608, 608) # multiple of 32, hw\n",
    "    model_path = 'yolo4_weight.h5'\n",
    "    #model_path = 'logs/000/'+'ep001-loss5261.659.h5'\n",
    "    #model_path = 'logs-neck/000/'+'ep050-loss5.966.h5' # neck for voc2012\n",
    "    model, model_body = create_model(input_shape, anchors_stride_base, num_classes,\n",
    "      load_pretrained=False, freeze_body=2,\n",
    "      weights_path=model_path)\n",
    "\n",
    "    logging = TensorBoard(log_dir=log_dir)\n",
    "    checkpoint = ModelCheckpoint(log_dir + 'ep{epoch:03d}-loss{loss:.3f}.h5',\n",
    "        monitor='loss', save_weights_only=True, save_best_only=True, period=1)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=3, verbose=1)\n",
    "    # learning rate를 줄여가면서 확인\n",
    "    early_stopping = EarlyStopping(monitor='loss', min_delta=0, patience=10, verbose=1)\n",
    "    evaluation = Evaluate(model_body=model_body, anchors=anchors, class_names=class_index, score_threshold=0.05,\n",
    "        tensorboard=logging, weighted_average=True, eval_file=annotation_val_path, log_dir=log_dir)\n",
    "\n",
    "    with open(annotation_train_path) as f:\n",
    "        lines_train = f.readlines()\n",
    "    np.random.seed(10101)\n",
    "    np.random.shuffle(lines_train)\n",
    "    np.random.seed(None)\n",
    "    num_train = len(lines_train)\n",
    "\n",
    "    with open(annotation_val_path) as f:\n",
    "        lines_val = f.readlines()\n",
    "    np.random.seed(10101)\n",
    "    np.random.shuffle(lines_val)\n",
    "    np.random.seed(None)\n",
    "    num_val = len(lines_val)\n",
    "    # Train with frozen layers first, to get a stable loss.\n",
    "    # Adjust num epochs to your dataset. This step is enough to obtain a not bad model.\n",
    "    if True:\n",
    "        model.compile(optimizer=Adam(lr=1e-3), loss={'yolo_loss': lambda y_true, y_pred: y_pred})\n",
    "\n",
    "        batch_size = 8\n",
    "        print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
    "        #model.fit_generator(data_generator_wrapper(lines_train[:num_train], batch_size, input_shape, anchors, num_classes),\n",
    "        #model.fit_generator(data_generator_wrapper(lines_train, batch_size, anchors_stride_base, num_classes, max_bbox_per_scale, 'train'),\n",
    "        model.fit(data_generator_wrapper(lines_train, batch_size, anchors_stride_base, num_classes, max_bbox_per_scale, 'train'),\n",
    "                steps_per_epoch=max(1, num_train//batch_size),\n",
    "                epochs=500, # backbone 부분을 freeze >> head 부분만 학습\n",
    "                initial_epoch=0,\n",
    "                \n",
    "                callbacks=[logging, checkpoint, reduce_lr, early_stopping, evaluation])\n",
    "\n",
    "    # Unfreeze and continue training, to fine-tune.\n",
    "    # Train longer if the result is not good.\n",
    "    # if True:\n",
    "    #     for i in range(len(model.layers)):\n",
    "    #         model.layers[i].trainable = True\n",
    "    #     model.compile(optimizer=Adam(lr=1e-5), loss={'yolo_loss': lambda y_true, y_pred: y_pred}) # recompile to apply the change\n",
    "    #     print('Unfreeze all of the layers.')\n",
    "\n",
    "    #     batch_size = 4 # note that more GPU memory is required after unfreezing the body\n",
    "    #     #batch_size = 2 # note that more GPU memory is required after unfreezing the body\n",
    "    #     print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
    "    #     model.fit_generator(data_generator_wrapper(lines_train, batch_size, anchors_stride_base, num_classes, max_bbox_per_scale, 'train'),\n",
    "    #         steps_per_epoch=max(1, num_train//batch_size),\n",
    "    #         epochs=5000,\n",
    "    #         initial_epoch=50,\n",
    "    #         callbacks=[logging, checkpoint, reduce_lr, early_stopping, evaluation])\n",
    "\n",
    "    # # Further training if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please visit https://github.com/miemie2013/Keras-YOLOv4 for more complete model!\n",
      "Create YOLOv4 model with 9 anchors and 2 classes.\n",
      "WARNING:tensorflow:From C:\\Users\\SBAUser\\AppData\\Local\\Temp\\ipykernel_14196\\1663215791.py:214: Print (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2018-08-20.\n",
      "Instructions for updating:\n",
      "Use tf.print instead of tf.Print. Note that tf.print returns a no-output operator that directly prints the output. Outside of defuns or eager mode, this operator will not be executed unless it is directly specified in session.run or used as a control dependency for other operators. This is only a concern in graph mode. Below is an example of how to ensure tf.print executes in graph mode:\n",
      "\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Train on 2019 samples, val on 500 samples, with batch size 8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'model_2/batch_normalization_7/FusedBatchNormV3' defined at (most recent call last):\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelapp.py\", line 728, in start\n      self.io_loop.start()\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\ipkernel.py\", line 423, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 2945, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3000, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3203, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3382, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3442, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\SBAUser\\AppData\\Local\\Temp\\ipykernel_14196\\2124392183.py\", line 1, in <module>\n      _main()\n    File \"C:\\Users\\SBAUser\\AppData\\Local\\Temp\\ipykernel_14196\\2882171376.py\", line 76, in _main\n      model.fit(data_generator_wrapper(lines_train, batch_size, anchors_stride_base, num_classes, max_bbox_per_scale, 'train'),\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 850, in call\n      outputs = self._fused_batch_norm(inputs, training=training)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 660, in _fused_batch_norm\n      output, mean, variance = control_flow_util.smart_cond(\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\control_flow_util.py\", line 108, in smart_cond\n      return tf.__internal__.smart_cond.smart_cond(\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 634, in _fused_batch_norm_training\n      return tf.compat.v1.nn.fused_batch_norm(\nNode: 'model_2/batch_normalization_7/FusedBatchNormV3'\nDetected at node 'model_2/batch_normalization_7/FusedBatchNormV3' defined at (most recent call last):\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelapp.py\", line 728, in start\n      self.io_loop.start()\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\ipkernel.py\", line 423, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 2945, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3000, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3203, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3382, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3442, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\SBAUser\\AppData\\Local\\Temp\\ipykernel_14196\\2124392183.py\", line 1, in <module>\n      _main()\n    File \"C:\\Users\\SBAUser\\AppData\\Local\\Temp\\ipykernel_14196\\2882171376.py\", line 76, in _main\n      model.fit(data_generator_wrapper(lines_train, batch_size, anchors_stride_base, num_classes, max_bbox_per_scale, 'train'),\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 850, in call\n      outputs = self._fused_batch_norm(inputs, training=training)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 660, in _fused_batch_norm\n      output, mean, variance = control_flow_util.smart_cond(\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\control_flow_util.py\", line 108, in smart_cond\n      return tf.__internal__.smart_cond.smart_cond(\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 634, in _fused_batch_norm_training\n      return tf.compat.v1.nn.fused_batch_norm(\nNode: 'model_2/batch_normalization_7/FusedBatchNormV3'\n2 root error(s) found.\n  (0) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[8,64,240,240] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_2/batch_normalization_7/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[model_2/yolo_loss/ArithmeticOptimizer/AddOpsRewrite_add_51/_134]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[8,64,240,240] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_2/batch_normalization_7/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_33996]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m _main()\n",
      "Cell \u001b[1;32mIn[12], line 76\u001b[0m, in \u001b[0;36m_main\u001b[1;34m()\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTrain on \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m samples, val on \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m samples, with batch size \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(num_train, num_val, batch_size))\n\u001b[0;32m     74\u001b[0m \u001b[39m#model.fit_generator(data_generator_wrapper(lines_train[:num_train], batch_size, input_shape, anchors, num_classes),\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[39m#model.fit_generator(data_generator_wrapper(lines_train, batch_size, anchors_stride_base, num_classes, max_bbox_per_scale, 'train'),\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m model\u001b[39m.\u001b[39;49mfit(data_generator_wrapper(lines_train, batch_size, anchors_stride_base, num_classes, max_bbox_per_scale, \u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[0;32m     77\u001b[0m         steps_per_epoch\u001b[39m=\u001b[39;49m\u001b[39mmax\u001b[39;49m(\u001b[39m1\u001b[39;49m, num_train\u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49mbatch_size),\n\u001b[0;32m     78\u001b[0m         epochs\u001b[39m=\u001b[39;49m\u001b[39m500\u001b[39;49m, \u001b[39m# backbone 부분을 freeze >> head 부분만 학습\u001b[39;49;00m\n\u001b[0;32m     79\u001b[0m         initial_epoch\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[0;32m     80\u001b[0m         \n\u001b[0;32m     81\u001b[0m         callbacks\u001b[39m=\u001b[39;49m[logging, checkpoint, reduce_lr, early_stopping, evaluation])\n",
      "File \u001b[1;32mc:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model_2/batch_normalization_7/FusedBatchNormV3' defined at (most recent call last):\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelapp.py\", line 728, in start\n      self.io_loop.start()\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\ipkernel.py\", line 423, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 2945, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3000, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3203, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3382, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3442, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\SBAUser\\AppData\\Local\\Temp\\ipykernel_14196\\2124392183.py\", line 1, in <module>\n      _main()\n    File \"C:\\Users\\SBAUser\\AppData\\Local\\Temp\\ipykernel_14196\\2882171376.py\", line 76, in _main\n      model.fit(data_generator_wrapper(lines_train, batch_size, anchors_stride_base, num_classes, max_bbox_per_scale, 'train'),\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 850, in call\n      outputs = self._fused_batch_norm(inputs, training=training)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 660, in _fused_batch_norm\n      output, mean, variance = control_flow_util.smart_cond(\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\control_flow_util.py\", line 108, in smart_cond\n      return tf.__internal__.smart_cond.smart_cond(\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 634, in _fused_batch_norm_training\n      return tf.compat.v1.nn.fused_batch_norm(\nNode: 'model_2/batch_normalization_7/FusedBatchNormV3'\nDetected at node 'model_2/batch_normalization_7/FusedBatchNormV3' defined at (most recent call last):\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelapp.py\", line 728, in start\n      self.io_loop.start()\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\ipkernel.py\", line 423, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 2945, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3000, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3203, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3382, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\SBAUser\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3442, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\SBAUser\\AppData\\Local\\Temp\\ipykernel_14196\\2124392183.py\", line 1, in <module>\n      _main()\n    File \"C:\\Users\\SBAUser\\AppData\\Local\\Temp\\ipykernel_14196\\2882171376.py\", line 76, in _main\n      model.fit(data_generator_wrapper(lines_train, batch_size, anchors_stride_base, num_classes, max_bbox_per_scale, 'train'),\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 850, in call\n      outputs = self._fused_batch_norm(inputs, training=training)\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 660, in _fused_batch_norm\n      output, mean, variance = control_flow_util.smart_cond(\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\control_flow_util.py\", line 108, in smart_cond\n      return tf.__internal__.smart_cond.smart_cond(\n    File \"c:\\Users\\SBAUser\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 634, in _fused_batch_norm_training\n      return tf.compat.v1.nn.fused_batch_norm(\nNode: 'model_2/batch_normalization_7/FusedBatchNormV3'\n2 root error(s) found.\n  (0) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[8,64,240,240] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_2/batch_normalization_7/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[model_2/yolo_loss/ArithmeticOptimizer/AddOpsRewrite_add_51/_134]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[8,64,240,240] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_2/batch_normalization_7/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_33996]"
     ]
    }
   ],
   "source": [
    "_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
